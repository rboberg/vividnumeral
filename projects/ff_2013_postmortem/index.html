<!DOCTYPE html PUBLIC "" "">
<HTML>
<HEAD>
	<META content="IE=10.000" http-equiv="X-UA-Compatible">
	<META charset="utf-8">  <!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame Remove this if you use the .htaccess --> 
	<META http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<!--  Mobile viewport optimized: j.mp/bplateviewport --> 
	<META name="viewport" content="width=device-width, initial-scale=1.0">
	<META name="GENERATOR" content="MSHTML 10.00.9200.16635">


	<TITLE>2013 Fantasy Post-Mortem</TITLE>   
	<META name="description" content="A look back at whether my systematic, quantitative approach to the 2013 Fantasy Football draft was actually any good.">   	
	<META name="date_posted" content="1986/12/05">
	<META name="author" content="Ross Boberg">
	<LINK href="../../style/article.css" rel="stylesheet" type="text/css"></LINK>
	<LINK href="webfiles/style.css" rel="stylesheet" type="text/css"></LINK>
	
	
</HEAD>

<BODY>
	<DIV id="content">

		<DIV id="page_header">
			<H1>2013 Fantasy Football Post-Mortem</H1>
			<p><a href="../../">Home</a></p>
		</DIV>

		<DIV id="main_text">

			<h2>Nerd Level : 1</h2>

			<p>
			Before the 2013 Football season I wrote a couple pieces detailing a quantitative fantasy draft methodology. You can find the details <a href='../ff_rank'>here</a> , but, in short, I used player stat projections aggregated by <a href='http://www.fantasypros.com'>fantasypros.com</a> and some adjustments to compare players across positions to quantify each player's value. With the season in the rear-view mirror, I want to know whether it was worth the trouble.	
			</p>
			
			<p>
			I'm feeling pretty good about the model since all three of my fantasy teams were first or second this year. But that's a very small sample size and a ton of other factors that could effect that outcome (like luck). This article takes a more robust look at whether it was a waste of time.
			</p>
			
			<p>
			The punch line is that the expert estimate based draft ranks added between 4 and 7 points per game over just using ESPN's Average Draft Position to determine picks. That is statistically significant. I broke this article in to Nerd Levels: increasing degrees of method detail and quantitative complexity. So you can take my word that this method adds value, stop reading, and send me a congratulatory email or move on to Level 2.
			</p>

			<h2>Nerd Level : 2</h2>

			<p>
				To quantify the points added by my method, I ran a mock draft of a 12 team leage where 6 teams pick according to ESPN's pre-season average draft position (ADP) and 6 teams pick the the player with the best expert consensus value. I'll refer to the two types as ADP and Value Based going forward. Once the rosters were set, I calculated how many points each team would have scored over the sytem
			</p>

			<p>
				If you're unusually interested, intrepid, or bored you can find more detail on the draft methodology here **INSERT LINK TO DRAFT METHODOLOGY HERE**. You can also find the R code used on GitHub **INSERT rross GITHUB LINK**.
			</p>

			<h3>Broad Results</h3>

			<p>
				Once I have the points scored by each team there are a couple ways to translate that in to a weekly point difference between the two mehtods.
			</p>

			<ol>
				<li>
				Average the weekkly points of the players at each position for each strategy. Then multiply by the number of starters at each position. This way, the Value Based teams averaged 4.4 points per week more than the ADP teams.
				</li>
				<li>
				Same as method one, but instead of averaging the points of all players, only average the points of players that would have started. This way, the Value Based teams averaged 6.2 points per week more than the ADP teams.
				</li>
			</ol>
			<p>
				The second method throws out the worst outliers from each strategy's draft, so flukes like a player getting injured for the entire season in week 1 will not overly effect the results. This method is also more foregiving of high risk / high reward picks that don't pan out.
			</p>
			<p>
				With 6.2 points per week instead of 4.4, method two is more flattering of the Value Based method. The main reason for the difference is Josh Freeman. The the Value Based system drafted him, and his almost non-existant season gets included in method one but thrown out in method two, because there's no way he would have started. More on that later.
			</p>

			<p>
				It's possible I was just lucky that the Value Based approach added around 5 points per week. But it seems unlikely. This table summarizes the stastical significance of the results for each calculation method.
			</p>



			<div id='broad_table'>
				<table>
					<tr>
						<th colspan='100'>Weekly Points of Value Based over ADP</th>
					</tr>
					<tr>
						<th rowspan='2' class='tdtext'>Method</th>
						<th colspan='3' style='border:none'>95% Confidence Interval</th>
						<th rowspan='2' class='tdvalue'>Probability<br>Points > 0</th>
					</tr>
					<tr>
						<th class='tdvalue'>Low</th>
						<th class='tdvalue'>Mean</th>
						<th class='tdvalue'>High</th>
					</tr>
					<tr>
						<td class='tdtext'>(1) All Players</td>
						<td class='tdvalue'>-0.8</td>
						<td class='tdvalue'>4.4</td>
						<td class='tdvalue'>9.6</td>
						<td class='tdvalue'>95.6%</td>
					</tr>
					<tr>
						<td class='tdtext'>(2) Starters Only</td>
						<td class='tdvalue'>1.6</td>
						<td class='tdvalue'>6.2</td>
						<td class='tdvalue'>10.8</td>
						<td class='tdvalue'>99.7%</td>
					</tr>
				</table>
			</div>

			<p>
				The probability that the Value Based approach added positive points over ADP is greater than 95% for both calculation methods. 95% is usually good enough for scholarly articles, so I'll take it.
			</p>

			<h2> Nerd Level : 3</h2>

			<p>
				There's lots of questions to ask about how these extra points are being generated. How are the extra points being generated? What did the method do right? Where did it screw up?  Breaking down the points added by position is a way to start answering these questions.
			</p>

			<div id='position_table'>

			</div>

			<p>
				The weak spot in the Value Based drafting is highlighted by the red in the table above.
				With only starters included, I added positive value at QB, but it's still the smallest of any position.
				What happened?
			</p>

			<p>
				ADD VISUALIZATION & EXPLANATION	
			</p>

			<div id='draft_viz'>
				
			</div>

			<p>
				This visualization provides more granularity about the draft.
				If you filter on QB's you can see the problem was underestimating the excellence of Peyton Manning and Drew Brees.
				You can also see that the relative improvement in the "Starters Only" method is a result of dropping Josh Freeman from the evaluation. Providing almost no points and the high point scoring positiong, he was by far the worst pick of the draft.
			</p>

			<p>
				(WARNING: THE FOLLOWING PARAGRAPH CONTAINS CONFUSING AND UNNECCESARY ABBREVIATIONS, DO NOT OPERATE HEAVY MACHINERY WHILE READING)
			</p>
			<p>
				ADP correctly drafted the MVFP (most valuable fantasy player) and MVRP (most valuable reality player) Peyton Manning. I also missed 3MVFP (3rd most valuable fantasy player) Drew Brees. Those misses hurt my QB cred.

			</p>

			<p>
				However the next 10 or so QBs drafted all produced about the same value. I waited until late to draft those QBs while ADP took them early. That earned back a bit of my QB cred.
			</p>

			<p>
				I also did very well picking the most value RBs (top 3) and TEs.
			</p>

			<h2> Nerd Level : 4</h2>

			<p>
				The number of points garnered at each position can be broken down in to two sources: Position Preference and Player Choice.
			</p>

			<h3>(1) Position Preference</h3>

			<p>
				Position Preference is the value derived from drafting a position early or late.
				For example, if I draft running backs early I should get more points from running backs than my opposition, regardless of how good I am at choosing between running backs.
				But, I give up points at other positions by going after RBs aggressively.
			</p>

			<p>
				However, I can net add value throughout my roster by drafting a position early if the skill generally drops off fastest at that position. In other words, if the marginal value of drafting early at that position is greater than the other positions. 
			</p>

			<p>ADD TABLE AND EXPLANATION (LINEAR REGRESSION ETC)</p>

			<h3>(2) Player Choice</h3>

			<p>
				Player Choice is the value derived from drafting better players with the same pick as your opponents.
				For example, if I consistently pick better running backs one pick after other people in the league, then I am adding value by Player Choice. This is the number of points that cannot be explained by Position Preference.
			</p>

			<p> ADD TABLE AND EXPLANATION (RESIDUAL OF LINEAR REGRESSION ETC)</p>

			<h2>Lessons</h2>
				<p>
					This value based method seems to consistently beat just drafting according to the average draft position. It doesn't always smake the best choice, as can be seeing by missing out on gigantic years by Peyton Manning and Drew Brees, but it consistently adds value across positions and throughout the draft.
				</p>
				<p>
					I'll be using this methodology next year, maybe with some added wrinkles. This year I only used the average projection in ranking players. Information about the uncertainty of projections might add value. For example, if the distribution of expert projections are all over the place, that might suggest the player is a risky pick and I can downgrade the rank accordingly.
				</p>
				<p>
					Another area where I could improve would be more dynamic benchmarking. Comparing players within positions is pretty easy. If Adrian Peterson is projected to have more points than Arian Foster, take Adrian Peterson. But choosing BETWEEN positions is difficult.
				</p>
				<p>
					To choose whether a player at one position is better than another, you have to adjust their projected points scored to try to make their values comparable. This year I used the worst player I might end up with at a position as the benchmark, but that can be improved.
				</p>
				<p>
					A better benchmark might be the player I can get next round if I refrain from drafting this player this round. The intuition is, if the first 10 wide receivers are all projected about the same, it makes sense to take another position and wait until next round to take a wide receiver.
				</p>
		<DIV>
	</DIV>


<!-- SCRIPT GOES HERE-->
	<script src="webfiles/d3.js"></script>
	<script src="webfiles/underscore-min.js"></script>
	<script src="webfiles/jquery-min.js"></script>
	<script src="webfiles/main.js"></script>

</BODY>
</HTML>